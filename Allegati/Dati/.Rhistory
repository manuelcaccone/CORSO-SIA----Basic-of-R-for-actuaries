B=cbind(A,R2=c(summary(model3)$r.squared,rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(summary(model3)$fstatistic[1],rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
kable(t(D),digits = 3)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
B=cbind(A,R2=c(summary(model3)$r.squared,rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(summary(model3)$fstatistic[1],rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
kable(t(D),"pipe")
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
B=cbind(A,R2=c(summary(model3)$r.squared,rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(summary(model3)$fstatistic[1],rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
kable(t(D),"simple")
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
B=cbind(A,R2=c(summary(model3)$r.squared,rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(summary(model3)$fstatistic[1],rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
kable(t(D),digits = rep(3,4))
round(D,4)
D
summary(model3)
A=tidy(summary(model3))
A
round(A,4)
apply(A[,-1],2,round)
A[,-1]=apply(A[,-1],2,round,digits =3)
A
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(summary(model3)$r.squared,rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(summary(model3)$fstatistic[1],rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
kable(t(D))
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(model3)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(model3)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
kable(t(D))
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(model3)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(model3)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
kable(t(D))
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(model3)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(model3)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
kable(tidy(t(D)))
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(model3)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(model3)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(model3)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(model3)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
which(data2$CA>0)
which(data2$CA<0)
data3=data2[which(data2$CA>0),]
data3=data2[which(data2$CA>0),]
data3=data2[which(data2$CA>0),]
M1=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data3)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(M1))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M1)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M1)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M1)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 2')
A=tidy(summary(M1))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M1)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M1)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M1)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 2')
A=tidy(summary(M1))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M1)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M1)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M1)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data4=data2[which(data2$CA<0),]
M1=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data4)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 3')
A=tidy(summary(M2))
data4=data2[which(data2$CA<0),]
M2=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data4)
summary(M2)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 3')
A=tidy(summary(M2))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M2)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M2)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M2)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
knitr::opts_chunk$set(echo = TRUE)
### Setting working Directory
setwd("C:\\Users\\UGA05153\\Desktop\\Personal\\Volpe")
### import data
#### Adding data ####
dati= readxl::read_excel("Dati.xlsx",na = '999999',sheet = 'Dati')
dati=data.frame(dati)
library(naniar)
library(UpSetR)
dati %>%
as_shadow_upset() %>%
upset()
data=data.frame(CA=dati$Change_TA,CPM=dati$Change_PM,ROA=dati$ROA_t.1,LEV=dati$Leverage_t,ASSET=dati$Asset)
rownames(data)=dati$`Ragione sociale`
library(missRanger)
for(i in 1:dim(data)[2]) data[,i]=missRanger::imputeUnivariate(data[,i])
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
my.summary <- function(x, na.rm=TRUE){
result <- c(Mean=mean(x, na.rm=na.rm),
SD=sd(x, na.rm=na.rm),
Median=median(x, na.rm=na.rm),
Min=min(x, na.rm=na.rm),
Max=max(x, na.rm=na.rm),
N=length(x))
}
ind <- sapply(data, is.numeric)
pandoc.table(round(sapply(data, my.summary),4))
attach(data)
h <- hist(CA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(CA), max(CA), length = 40)
yfit <- dnorm(xfit, mean = mean(CA), sd = sd(CA))
yfit <- yfit * diff(h$mids[1:2]) * length(CA)
lines(xfit, yfit, col = "black", lwd = 2)
attach(data)
trasforma=function(x){
logCA=log(x)
pos1=which((!is.na(logCA)) & (logCA!=-Inf & logCA!= Inf))
assign('pos_trasf', pos1, envir = .GlobalEnv)
logCA=logCA[which(!is.na(logCA))]
logCA=logCA[which(logCA!=-Inf & logCA!= Inf)]
logCA
}
logCA=trasforma(CA)
h <- hist(logCA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(logCA), max(logCA), length = 40)
yfit <- dnorm(xfit, mean = mean(logCA), sd = sd(logCA))
yfit <- yfit * diff(h$mids[1:2]) * length(logCA)
lines(xfit, yfit, col = "black", lwd = 2)
detach(data)
boxplot(apply(data,2,trasforma),col = rainbow(dim(data)[2]))
pairs(data)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
pandoc.table(round(cor(data),2))
model<-lm('CA~ CPM + ROA + LEV + log(ASSET)', data=data)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model))
model2<-lm(CA~ CPM + ROA + LEV + offset(log(ASSET)), data=data)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model2))
plot( model, which = 4)
cooksd <- cooks.distance(model)
# Plot the Cook's Distance using the traditional 4/n criterion
sample_size <- nrow(data)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add labels
pos=ifelse(cooksd>4/sample_size, names(cooksd),"")
pos=pos[which(pos!='')]
data2=data[-as.numeric(pos),]
attach(data2)
h <- hist(CA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(CA), max(CA), length = 40)
yfit <- dnorm(xfit, mean = mean(CA), sd = sd(CA))
yfit <- yfit * diff(h$mids[1:2]) * length(CA)
lines(xfit, yfit, col = "black", lwd = 2)
detach(data2)
model3<-lm(CA~ CPM + ROA + LEV + log(ASSET), data=data2)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model3))
detect_OL=function(x,h){
qnt <- quantile(x, probs=c(0.5-h/2, 0.5+h/2), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
ol=c(x[x < (qnt[1] - H)],x[x > (qnt[2] + H)])
return(match(ol,x))
}
l=apply(data2[,-which(colnames(data2)=='CA')],2,detect_OL,h=0.4)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
A=sapply(l, function(x) sapply(l, function(y) length(intersect(x,y))))
pandoc.table(A)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
l=apply(data2[,-which(colnames(data2)=='CA' | colnames(data2)=='ASSET' | colnames(data2)=='LEV' )],2,detect_OL,h=0.4)
A=sapply(l, function(x) sapply(l, function(y) length(intersect(x,y))))
pandoc.table(A)
model3=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data2)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model3))
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(model3)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(model3)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data3=data2[which(data2$CA>0),]
M1=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data3)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 2')
A=tidy(summary(M1))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M1)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M1)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M1)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data4=data2[which(data2$CA<0),]
M2=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data4)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 3')
A=tidy(summary(M2))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M2)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M2)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M2)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data3
knitr::opts_chunk$set(echo = TRUE)
### Setting working Directory
setwd("C:\\Users\\UGA05153\\Desktop\\Personal\\Volpe")
### import data
#### Adding data ####
dati= readxl::read_excel("Dati.xlsx",na = '999999',sheet = 'Dati')
dati=data.frame(dati)
library(naniar)
library(UpSetR)
dati %>%
as_shadow_upset() %>%
upset()
data=data.frame(CA=dati$Change_TA,CPM=dati$Change_PM,ROA=dati$ROA_t.1,LEV=dati$Leverage_t,ASSET=dati$Asset,NDA=dati$NDA)
rownames(data)=dati$`Ragione sociale`
library(missRanger)
for(i in 1:dim(data)[2]) data[,i]=missRanger::imputeUnivariate(data[,i])
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
my.summary <- function(x, na.rm=TRUE){
result <- c(Mean=mean(x, na.rm=na.rm),
SD=sd(x, na.rm=na.rm),
Median=median(x, na.rm=na.rm),
Min=min(x, na.rm=na.rm),
Max=max(x, na.rm=na.rm),
N=length(x))
}
ind <- sapply(data, is.numeric)
pandoc.table(round(sapply(data, my.summary),4))
attach(data)
h <- hist(CA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(CA), max(CA), length = 40)
yfit <- dnorm(xfit, mean = mean(CA), sd = sd(CA))
yfit <- yfit * diff(h$mids[1:2]) * length(CA)
lines(xfit, yfit, col = "black", lwd = 2)
attach(data)
trasforma=function(x){
logCA=log(x)
pos1=which((!is.na(logCA)) & (logCA!=-Inf & logCA!= Inf))
assign('pos_trasf', pos1, envir = .GlobalEnv)
logCA=logCA[which(!is.na(logCA))]
logCA=logCA[which(logCA!=-Inf & logCA!= Inf)]
logCA
}
logCA=trasforma(CA)
h <- hist(logCA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(logCA), max(logCA), length = 40)
yfit <- dnorm(xfit, mean = mean(logCA), sd = sd(logCA))
yfit <- yfit * diff(h$mids[1:2]) * length(logCA)
lines(xfit, yfit, col = "black", lwd = 2)
detach(data)
boxplot(apply(data,2,trasforma),col = rainbow(dim(data)[2]))
pairs(data)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
pandoc.table(round(cor(data),2))
model<-lm('CA~ CPM + ROA + LEV + log(ASSET)', data=data)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model))
model2<-lm(CA~ CPM + ROA + LEV + offset(log(ASSET)), data=data)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model2))
plot( model, which = 4)
cooksd <- cooks.distance(model)
# Plot the Cook's Distance using the traditional 4/n criterion
sample_size <- nrow(data)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add labels
pos=ifelse(cooksd>4/sample_size, names(cooksd),"")
pos=pos[which(pos!='')]
data2=data[-as.numeric(pos),]
attach(data2)
h <- hist(CA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(CA), max(CA), length = 40)
yfit <- dnorm(xfit, mean = mean(CA), sd = sd(CA))
yfit <- yfit * diff(h$mids[1:2]) * length(CA)
lines(xfit, yfit, col = "black", lwd = 2)
detach(data2)
model3<-lm(CA~ CPM + ROA + LEV + log(ASSET), data=data2)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model3))
detect_OL=function(x,h){
qnt <- quantile(x, probs=c(0.5-h/2, 0.5+h/2), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
ol=c(x[x < (qnt[1] - H)],x[x > (qnt[2] + H)])
return(match(ol,x))
}
l=apply(data2[,-which(colnames(data2)=='CA')],2,detect_OL,h=0.4)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
A=sapply(l, function(x) sapply(l, function(y) length(intersect(x,y))))
pandoc.table(A)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
l=apply(data2[,-which(colnames(data2)=='CA' | colnames(data2)=='ASSET' | colnames(data2)=='LEV' )],2,detect_OL,h=0.4)
A=sapply(l, function(x) sapply(l, function(y) length(intersect(x,y))))
pandoc.table(A)
model3=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data2)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model3))
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(model3)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(model3)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data3=data2[which(data2$CA>0),]
M1=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data3)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 2')
A=tidy(summary(M1))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M1)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M1)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M1)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data4=data2[which(data2$CA<0),]
M2=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data4)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 3')
A=tidy(summary(M2))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M2)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M2)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M2)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
library(pander)
M=lm(formula = NDA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data2)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 3')
A=tidy(summary(M))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
knitr::opts_chunk$set(echo = FALSE)
library(sqldf)
sqldf("select * from iris limit 5")
sqldf("select count(*) from iris")
sqldf("select Species, count(*) from iris group by Species")
DF <- data.frame(a = 1:5, b = letters[1:5])
sqldf("select * from DF")
sqldf("select avg(a) mean, var_samp(a) var from DF")
library(RH2)
install.packages("RH2")
library(sqldf)
library(RH2)
sqldf("select * from iris limit 5")
sqldf("select count(*) from iris")
sqldf("select Species, count(*) from iris group by Species")
DF <- data.frame(a = 1:5, b = letters[1:5])
sqldf("select * from DF")
sqldf("select avg(a) mean, var_samp(a) var from DF")
library(dplyr)
suppressPackageStartupMessages({library(dplyr)})
starwars %>%
filter(species == "Droid")
head(starwars)
suppressPackageStartupMessages({library(dplyr)})
head(starwars[,c('species')])
suppressPackageStartupMessages({library(dplyr)})
head(starwars[,c('species')])
starwars %>%
filter(species == "Droid")
starwars %>%
mutate(name, bmi = mass / ((height / 100)  ^ 2)) %>%
select(name:mass, bmi)
starwars_1= starwars %>%
mutate(name, bmi = mass / ((height / 100)  ^ 2)) %>%
select(name:mass, bmi)
head(starwars_1,3)
starwars_2=starwars %>%
group_by(species) %>%
summarise(
n = n(),
mass = mean(mass, na.rm = TRUE)
) %>%
filter(
n > 1,
mass > 50
)
head(starwars_2,3)
install.packages("RODBC")
library(RODBC)
# richiamo il pacchetto
library(RODBC)
setwd(readClipboard())
myChannell<- odbcConnectAccess2007("Database.accdb")
list.files()
