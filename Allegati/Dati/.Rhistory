require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model2))
plot( model, which = 4)
cooksd <- cooks.distance(model)
# Plot the Cook's Distance using the traditional 4/n criterion
sample_size <- nrow(data)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add labels
pos=ifelse(cooksd>4/sample_size, names(cooksd),"")
pos=pos[which(pos!='')]
data2=data[-as.numeric(pos),]
attach(data2)
h <- hist(CA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(CA), max(CA), length = 40)
yfit <- dnorm(xfit, mean = mean(CA), sd = sd(CA))
yfit <- yfit * diff(h$mids[1:2]) * length(CA)
lines(xfit, yfit, col = "black", lwd = 2)
detach(data2)
model3<-lm(CA~ CPM + ROA + LEV + log(ASSET), data=data2)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model3))
detect_OL=function(x,h){
qnt <- quantile(x, probs=c(0.5-h/2, 0.5+h/2), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
ol=c(x[x < (qnt[1] - H)],x[x > (qnt[2] + H)])
return(match(ol,x))
}
l=apply(data2[,-which(colnames(data2)=='CA')],2,detect_OL,h=0.4)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
A=sapply(l, function(x) sapply(l, function(y) length(intersect(x,y))))
pandoc.table(A)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
l=apply(data2[,-which(colnames(data2)=='CA' | colnames(data2)=='ASSET' | colnames(data2)=='LEV' )],2,detect_OL,h=0.4)
A=sapply(l, function(x) sapply(l, function(y) length(intersect(x,y))))
pandoc.table(A)
model3=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data2)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model3))
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(model3)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(model3)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data3=data2[which(data2$CA>0),]
M1=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data3)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 2')
A=tidy(summary(M1))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M1)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M1)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M1)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data4=data2[which(data2$CA<0),]
M2=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data4)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 3')
A=tidy(summary(M2))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M2)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M2)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M2)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data3
knitr::opts_chunk$set(echo = TRUE)
### Setting working Directory
setwd("C:\\Users\\UGA05153\\Desktop\\Personal\\Volpe")
### import data
#### Adding data ####
dati= readxl::read_excel("Dati.xlsx",na = '999999',sheet = 'Dati')
dati=data.frame(dati)
library(naniar)
library(UpSetR)
dati %>%
as_shadow_upset() %>%
upset()
data=data.frame(CA=dati$Change_TA,CPM=dati$Change_PM,ROA=dati$ROA_t.1,LEV=dati$Leverage_t,ASSET=dati$Asset,NDA=dati$NDA)
rownames(data)=dati$`Ragione sociale`
library(missRanger)
for(i in 1:dim(data)[2]) data[,i]=missRanger::imputeUnivariate(data[,i])
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
my.summary <- function(x, na.rm=TRUE){
result <- c(Mean=mean(x, na.rm=na.rm),
SD=sd(x, na.rm=na.rm),
Median=median(x, na.rm=na.rm),
Min=min(x, na.rm=na.rm),
Max=max(x, na.rm=na.rm),
N=length(x))
}
ind <- sapply(data, is.numeric)
pandoc.table(round(sapply(data, my.summary),4))
attach(data)
h <- hist(CA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(CA), max(CA), length = 40)
yfit <- dnorm(xfit, mean = mean(CA), sd = sd(CA))
yfit <- yfit * diff(h$mids[1:2]) * length(CA)
lines(xfit, yfit, col = "black", lwd = 2)
attach(data)
trasforma=function(x){
logCA=log(x)
pos1=which((!is.na(logCA)) & (logCA!=-Inf & logCA!= Inf))
assign('pos_trasf', pos1, envir = .GlobalEnv)
logCA=logCA[which(!is.na(logCA))]
logCA=logCA[which(logCA!=-Inf & logCA!= Inf)]
logCA
}
logCA=trasforma(CA)
h <- hist(logCA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(logCA), max(logCA), length = 40)
yfit <- dnorm(xfit, mean = mean(logCA), sd = sd(logCA))
yfit <- yfit * diff(h$mids[1:2]) * length(logCA)
lines(xfit, yfit, col = "black", lwd = 2)
detach(data)
boxplot(apply(data,2,trasforma),col = rainbow(dim(data)[2]))
pairs(data)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
pandoc.table(round(cor(data),2))
model<-lm('CA~ CPM + ROA + LEV + log(ASSET)', data=data)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model))
model2<-lm(CA~ CPM + ROA + LEV + offset(log(ASSET)), data=data)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model2))
plot( model, which = 4)
cooksd <- cooks.distance(model)
# Plot the Cook's Distance using the traditional 4/n criterion
sample_size <- nrow(data)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add labels
pos=ifelse(cooksd>4/sample_size, names(cooksd),"")
pos=pos[which(pos!='')]
data2=data[-as.numeric(pos),]
attach(data2)
h <- hist(CA, breaks = 10, density = 10,
col = "lightgray", xlab = "Accuracy", main = "Overall")
xfit <- seq(min(CA), max(CA), length = 40)
yfit <- dnorm(xfit, mean = mean(CA), sd = sd(CA))
yfit <- yfit * diff(h$mids[1:2]) * length(CA)
lines(xfit, yfit, col = "black", lwd = 2)
detach(data2)
model3<-lm(CA~ CPM + ROA + LEV + log(ASSET), data=data2)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model3))
detect_OL=function(x,h){
qnt <- quantile(x, probs=c(0.5-h/2, 0.5+h/2), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
ol=c(x[x < (qnt[1] - H)],x[x > (qnt[2] + H)])
return(match(ol,x))
}
l=apply(data2[,-which(colnames(data2)=='CA')],2,detect_OL,h=0.4)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
A=sapply(l, function(x) sapply(l, function(y) length(intersect(x,y))))
pandoc.table(A)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
l=apply(data2[,-which(colnames(data2)=='CA' | colnames(data2)=='ASSET' | colnames(data2)=='LEV' )],2,detect_OL,h=0.4)
A=sapply(l, function(x) sapply(l, function(y) length(intersect(x,y))))
pandoc.table(A)
model3=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data2)
require(broom) # for tidy()
require(knitr) # for kable()
cat('Modello regressione lineare: Modello Saturo')
kable(tidy(model3))
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 1')
A=tidy(summary(model3))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(model3)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(model3)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(model3)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data3=data2[which(data2$CA>0),]
M1=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data3)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 2')
A=tidy(summary(M1))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M1)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M1)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M1)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
data4=data2[which(data2$CA<0),]
M2=lm(formula = CA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data4)
library(pander)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 3')
A=tidy(summary(M2))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M2)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M2)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M2)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
library(pander)
M=lm(formula = NDA ~ CPM + ROA + LEV + offset(log(ASSET)), data = data2)
panderOptions("table.style" , "rmarkdown")
panderOptions("table.split.table" , Inf)
cat('Modello regressione lineare: Modello 3')
A=tidy(summary(M))
A[,-1]=apply(A[,-1],2,round,digits =3)
B=cbind(A,R2=c(round(summary(M)$r.squared,3),rep('-',dim(A)[1]-1)))
C=cbind(B,F_Stat=c(round(summary(M)$fstatistic[1],3),rep('-',dim(A)[1]-1)))
D=cbind(C,N=c(summary(M)$df[2],rep('-',dim(A)[1]-1)))
pandoc.table(t(D))
knitr::opts_chunk$set(echo = FALSE)
library(sqldf)
sqldf("select * from iris limit 5")
sqldf("select count(*) from iris")
sqldf("select Species, count(*) from iris group by Species")
DF <- data.frame(a = 1:5, b = letters[1:5])
sqldf("select * from DF")
sqldf("select avg(a) mean, var_samp(a) var from DF")
library(RH2)
install.packages("RH2")
library(sqldf)
library(RH2)
sqldf("select * from iris limit 5")
sqldf("select count(*) from iris")
sqldf("select Species, count(*) from iris group by Species")
DF <- data.frame(a = 1:5, b = letters[1:5])
sqldf("select * from DF")
sqldf("select avg(a) mean, var_samp(a) var from DF")
library(dplyr)
suppressPackageStartupMessages({library(dplyr)})
starwars %>%
filter(species == "Droid")
head(starwars)
suppressPackageStartupMessages({library(dplyr)})
head(starwars[,c('species')])
suppressPackageStartupMessages({library(dplyr)})
head(starwars[,c('species')])
starwars %>%
filter(species == "Droid")
starwars %>%
mutate(name, bmi = mass / ((height / 100)  ^ 2)) %>%
select(name:mass, bmi)
starwars_1= starwars %>%
mutate(name, bmi = mass / ((height / 100)  ^ 2)) %>%
select(name:mass, bmi)
head(starwars_1,3)
starwars_2=starwars %>%
group_by(species) %>%
summarise(
n = n(),
mass = mean(mass, na.rm = TRUE)
) %>%
filter(
n > 1,
mass > 50
)
head(starwars_2,3)
setwd(readClipboard())
connect_to_access_dbi <- function(db_file_path)  {
require(DBI)
# make sure that the file exists before attempting to connect
if (!file.exists(db_file_path)) {
stop("DB file does not exist at ", db_file_path)
}
# Assemble connection strings
dbq_string <- paste0("DBQ=", db_file_path)
driver_string <- "Driver={Microsoft Access Driver (*.mdb, *.accdb)};"
db_connect_string <- paste0(driver_string, dbq_string)
myconn <- dbConnect(odbc::odbc(),
.connection_string = db_connect_string)
return(myconn)
}
connect_to_access_dbi("Database.accdb")
readClipboard()
# for 64 bit windows
channel <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=C:\\Users\\UGA05153\\Desktop\\CORSO-SIA----Basic-of-R-for-actuaries\\Allegati\\Dati\\Database.accdb")
# richiamo il pacchetto
library(RODBC)
# for 64 bit windows
channel <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=C:\\Users\\UGA05153\\Desktop\\CORSO-SIA----Basic-of-R-for-actuaries\\Allegati\\Dati\\Database.accdb")
# for 64 bit windows
channel <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=C:\\Users\\UGA05153\\Desktop\\CORSO-SIA----Basic-of-R-for-actuaries\\Allegati\\Dati\\Database.accdb")
connect_to_access_rodbc <- function(db_file_path) {
require(RODBC)
# make sure that the file exists before attempting to connect
if (!file.exists(db_file_path)) {
stop("DB file does not exist at ", db_file_path)
}
# Assemble connection strings
dbq_string <- paste0("DBQ=", db_file_path)
driver_string <- "Driver={Microsoft Access Driver (*.mdb, *.accdb)};"
db_connect_string <- paste0(driver_string, dbq_string)
myconn <- odbcDriverConnect(db_connect_string)
return(myconn)
}
connect_to_access_rodbc('C:\\Users\\UGA05153\\Desktop\\CORSO-SIA----Basic-of-R-for-actuaries\\Allegati\\Dati\\Database.accdb')
odbc::odbc()
# richiamo il pacchetto
library(RODBC)
library(UNISAIrp)
SCARICA_TAB
ODBC_str <- local({
s <- list()
s$path <- paste0("DBQ=", gsub("(/|\\\\)+", "/", path.expand(db_path)))
s$driver <- "Driver={Microsoft Access Driver (*.mdb, *.accdb)}"
s$threads <- paste0("Threads=", nThreads)
s$buffer <- "MaxBufferSize=4096"
s$timeout <- "PageTimeout=5"
paste(s, collapse = ";")
})
ODBC_str
# creo il mio canale ODBC
temp_directory=tempdir()
temp_directory
readClipboard(
)
writeClipboard(temp_directory)
system(paste0('curl.exe --output',paste0(temp_directory,'Db.accdb') ,' --url https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/blob/main/Allegati/Dati/Database.accdb?raw=true')
system(paste0('curl.exe --output',paste0(temp_directory,'Db.accdb') ,' --url https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/blob/main/Allegati/Dati/Database.accdb?raw=true'
))
system(paste0('curl.exe --output',paste0(temp_directory,'Db.accdb') ,' --url https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/blob/main/Allegati/Dati/Database.accdb?raw=true'
))
system(paste0('curl.exe --output',paste0(temp_directory,'\\Db.accdb') ,' --url https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/blob/main/Allegati/Dati/Database.accdb?raw=true'
))
system(paste0('curl.exe --url https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/blob/main/Allegati/Dati/Database.accdb?raw=true >',
paste0(temp_directory,'\\Db.accdb')
))
writeClipboard(temp_directory)
writeClipboard(paste0('curl.exe --url https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/blob/main/Allegati/Dati/Database.accdb?raw=true >',
paste0(temp_directory,'\\Db.accdb')
))
SCARICA_TAB
comando=paste0('curl.exe --url https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/blob/main/Allegati/Dati/Database.accdb?raw=true >',
paste0(temp_directory,'\\Db.accdb'))
system(paste0("cmd.exe /c ", comando),
intern = intern, wait = wait)
system(paste0("cmd.exe /c ", comando),
intern = TRUE, wait = FALSE)
# designo il path del file Access che ho scaricato
db_path=file.path(temp_directory,'Db.accdb')
db_path
ODBC_str <- local({
s <- list()
s$path <- paste0("DBQ=", gsub("(/|\\\\)+", "/", path.expand(db_path)))
s$driver <- "Driver={Microsoft Access Driver (*.mdb, *.accdb)}"
s$threads <- paste0("Threads=", nThreads)
s$buffer <- "MaxBufferSize=4096"
s$timeout <- "PageTimeout=5"
paste(s, collapse = ";")
})
ODBC_str
t2 = paste0("con1 <- odbcDriverConnect(\"", ODBC_str, "\");")
t2
writeClipboard(t1)
t2
writeClipboard(t2)
con1 <- odbcDriverConnect("DBQ=C:/Users/UGA05153/AppData/Local/Temp/RtmpuAql46/Db.accdb;Driver={Microsoft Access Driver (*.mdb, *.accdb)};Threads=8;MaxBufferSize=4096;PageTimeout=5");
system(paste0("cmd.exe /c ", comando),
intern = TRUE, wait = FALSE)
# designo il path del file Access che ho scaricato
db_path=file.path(temp_directory,'Db.accdb')
comando=paste0('curl.exe --url https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/raw/main/Allegati/Dati/Database.accdb >',
paste0(temp_directory,'\\Db.accdb'))
# imputo il mio comando al Prompt dei comandi cmd.exe
system(paste0("cmd.exe /c ", comando),
intern = TRUE, wait = FALSE)
writeClipboard(comando)
comando=paste0('curl.exe --url https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/blob/main/Allegati/Dati/Database.zip?raw=true >',
paste0(temp_directory,'\\Db.zip'))
writeClipboard(comando)
writeClipboard(temp_directory)
fileName <- "https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/blob/main/Allegati/Dati/Database.zip?raw=true"
con1 <- unz(fileName, filename="Db.accdb", open = "r")
fileName <- "https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/raw/main/Allegati/Dati/Database.zip"
con1 <- unz(fileName, filename="Db.accdb", open = "r")
download.file("https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/raw/main/Allegati/Dati/Database.zip",temp)
# scarico il database esempio
temp <- tempfile()
download.file("https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/raw/main/Allegati/Dati/Database.zip",temp)
tempfile
temp
writeClipboard(tmep)
writeClipboard(temp)
unz(temp, "Db.accdb")
bo=unz(temp, "Db.accdb")
bo
# designo il path del file Access che ho scaricato
db_path=unz(temp, "Db.accdb")
ODBC_str <- local({
s <- list()
s$path <- paste0("DBQ=", gsub("(/|\\\\)+", "/", path.expand(db_path)))
s$driver <- "Driver={Microsoft Access Driver (*.mdb, *.accdb)}"
s$threads <- paste0("Threads=", nThreads)
s$buffer <- "MaxBufferSize=4096"
s$timeout <- "PageTimeout=5"
paste(s, collapse = ";")
})
bo
str(bo)
attr(bo)
bo
scan(bo)
# scarico il database esempio
url="https://github.com/manuelcaccone/CORSO-SIA----Basic-of-R-for-actuaries/raw/main/Allegati/Dati/Database.zip"
download(url, dest="DB.zip", mode="wb")
# richiamo pacchetti necessari
library(RODBC)
library(downloader)
download(url, dest="DB.zip", mode="wb")
# scarico il database esempio
tmp_dir=tempdir()
# scarico il database esempio
tmp_dir=tempdir()
download(url, dest=file.path(tmp_dir,"DB.zip"), mode="wb")
unzip (file.path(tmp_dir,"DB.zip"), exdir = "./")
unzip (file.path(tmp_dir,"DB.zip"), exdir = tmp_dir)
writeClipboard(tmp_dir)
tmp_dir
# designo il path del file Access che ho scaricato
db_path=file.path(tmp_dir, "Database.accdb")
t2
SCARICA_TAB()
SCARICA_TAB
t1=paste0("con1 <- odbcDriverConnect(\"", ODBC_str, "\");")
t1
eval(parse(text = t1))
#creo le aggregazioni dei ammontari di sinistri per assicurato e sistemo i nomi
ciaoAmt<-dcast.data.table(data=aggregatedClaims, value.var="amount", formula=patientId~category,fill=0)
rawToChar(as.raw(126)))
rawToChar(as.raw(126))
as.formula(paste0(patientId,rawToChar(as.raw(126))))
as.formula('patientId',rawToChar(as.raw(126))),'category')
??as.formula
ciaoAmt
setnames(ciaoNum, "Dentistry","amtDentistry")
setnames(ciaoNum, "Visits","amtVisits")
setnames(ciaoNum, "Mammography","amtMammography")
setnames(ciaoNum, "Analysis","amtAnalysis")
setnames(ciaoNum, "Diagnostics","amtDiagnostics")
setnames(ciaoNum, "Hospitalizations","amtHospitalizations")
policiesDT
policiesIds
policiesIds
policiesIds
bo=readxl::read_excel('C:\\Users\\UGA05153\\Documents\\Policies.xlsx')
bo$IdAnagrafica
bo=as.data.table(bo)
bo
bo=bo[IdAnagrafica]
bo=bo[IdAnagrafica %in% readClipboard()]
bo
readClipboard()
key=readClipboard()
key=readClipboard()
key
bo=readxl::read_excel('C:\\Users\\UGA05153\\Documents\\Policies.xlsx')
bo=as.data.table(bo)
bo=bo[IdAnagrafica %in% key]
bo
write.table(bo,'clipboard',sep='\t',row.names = F)
bo
write.table(bo,'clipboard',sep='\t',row.names = F)
db4Modeling<-merge(x=policiesDT,y=claimsDataFin, by="patientId",all.x=TRUE)
# Creiamo con una funzione il dataset pronto per il modello GLM
createDbForModeling<-function(category, db, ageVar="AgeAtInception")  {
if(ageVar=="AgeAtInception")  db<-db[,AgeAtInception:=round(AgeAtInception)]
numVar<-paste("num",category,sep="")
amtVar<-paste("amt",category,sep="")
commandTxt<-paste("db[,.(",amtVar," = sum(",amtVar,"), ",numVar," = sum(",numVar,")", ",policyYears= sum(policyYears)",")",",by=.(",ageVar,", Gender,Relation)]",sep="")
myOutDb<- eval(parse(text=commandTxt))
myOutDb<-as.data.frame.matrix(myOutDb)
return(myOutDb)
}
# carico il pacchetto necessario per applicare un GLM Tweedie
library(cplm)
library(rms)
library(tweedie)
library(tweedie)
